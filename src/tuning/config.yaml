# Start an experiment:
# nnictl create --config config.yaml --port 8080

# Stop all experiments:
# nnictl stop --all

experimentName: TestExperiment1

# Possibly you could write the search space in a separate json file
searchSpace:
  hidden_size_1: 
    _type: choice
    _value: [4, 8, 16, 32, 64, 128, 256]

  hidden_size_2: 
    _type: choice
    _value: [0, 4, 8, 16, 32, 64, 128]

  hidden_size_3: 
    _type: choice
    _value: [0, 4, 8, 16, 32, 64, 128]
  
  act_func: 
    _type: choice
    _value: ["ReLU", "LeakyReLU", "Sigmoid", "Tanh", "Softplus"]
  
  learning_rate: 
  #   _type: quniform
  #   _value: [0.005, 0.05, 0.01]
    _type: loguniform
    _value: [ 0.0001, 0.1 ]

  optimizer:
    _type: choice
    _value: ["SGD", "Adam", "RMSprop"]
  
  loss: 
    _type: choice
    _value:  ["SmoothL1Loss", "MSELoss"]
    
  momentum:
    _type: uniform
    _value: [ 0, 1 ]
  
  epochs:
    _type: quniform
    _value: [1, 200, 50] #Uniform distribution from lower bound to upper bound with steps of 50
  
  batch_size:
    _type: choice
    _value: [4, 8, 16, 32, 64, 128, 256]
    #_type: quniform
    #_value: [16, 256, 16]



trial_command: python3 tune.py
trial_code_directory: ../ #The path is relative to the config file (in this case, where is tune.py compared to config.yaml)
#trialGpuNumber: 1
experimentWorkingDirectory: ./nni-experiments
max_trial_number: 30 #With TPE, 20 trials are needed only to warm up. The max trial number should be way higher
trial_concurrency: 2
maxExperimentDuration: 20m #24h #use 10m for example if using minutes.
tuner:
  #name: TPE
  #class_args:
  #  optimize_mode: maximize
  name: Evolution # Evolutionary (genetic) algorithm
  classArgs:
    optimize_mode: maximize
    population_size: 10

training_service:
  platform: local
  #maxTrialNumberPerGpu: 2
  useActiveGpu: True  # NOTE: Use "true" if you are using an OS with graphical interface (e.g. Windows 10, Ubuntu desktop)
                       # Check the doc for details: https://nni.readthedocs.io/en/latest/reference/experiment_config.html#useactivegpu
