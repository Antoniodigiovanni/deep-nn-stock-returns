# Start an experiment:
# nnictl create --config config.yaml --port 8080

# Stop all experiments:
# nnictl stop --all

experimentName: TestExperiment1

# Possibly you could write the search space in a separate json file
searchSpace:
  hidden_size_1: 
    _type: choice
    _value: [4, 8, 16, 32, 64, 128]

  hidden_size_2: 
    _type: choice
    _value: [0, 4, 8, 16, 32]

  hidden_size_3: 
    _type: choice
    _value: [0, 4, 8, 16, 32]
  
  act_func: 
    _type: choice
    _value: ["ReLU", "LeakyReLU", "Sigmoid", "Tanh", "Softplus"]
  
  learning_rate: 
  #   _type: quniform
  #   _value: [0.005, 0.05, 0.01]
    _type: loguniform
    _value: [ 0.0001, 0.1 ]

  optimizer:
    _type: choice
    _value: ["SGD", "Adam", "RMSprop"]
  
  loss: 
    _type: choice
    _value:  ["SmoothL1Loss", "MSELoss"]
    
  momentum:
    _type: uniform
    _value: [ 0, 1 ]


trial_command: python3 tune.py
trial_code_directory: ../ #The path is relative to the config file (in this case, where is tune.py compared to config.yaml)
#trialGpuNumber: 1
experimentWorkingDirectory: ./nni-experiments
max_trial_number: 1 #With TPE, 20 trials are needed only to warm up. The max trial number should be way higher
trial_concurrency: 1
maxExperimentDuration: 24h #use 10m for example if using minutes.
tuner:
  name: TPE
  class_args:
    optimize_mode: maximize

training_service:
  platform: local
  #useActiveGpu: True  # NOTE: Use "true" if you are using an OS with graphical interface (e.g. Windows 10, Ubuntu desktop)
                       # Check the doc for details: https://nni.readthedocs.io/en/latest/reference/experiment_config.html#useactivegpu

maxTrialNumberPerGpu: 2
  useActiveGpu: false  # NOTE: Use "true" if you are using an OS with graphical interface (e.g. Windows 10, Ubuntu desktop)
                       # Check the doc for details: https://nni.readthedocs.io/en/latest/reference/experiment_config.html#useactivegpu
