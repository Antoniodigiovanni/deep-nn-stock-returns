{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add root folder to Python path (to import modules)\n",
    "notebook_dir = Path().absolute()\n",
    "project_root = notebook_dir.parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "path = '../saved/final_results/results_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(path, index_col=0)\n",
    "results_df = results_df.dropna()\n",
    "trials_list = results_df.trial_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "trials_df = pd.DataFrame()\n",
    "for trial in trials_list:\n",
    "    file_name = str(trial) + '_trial_full.json'\n",
    "    file_path = '../saved/final_results/trial_info/'\n",
    "    try:\n",
    "        with open(file_path+file_name) as f:\n",
    "            data = json.load(f)\n",
    "            params = data['params']\n",
    "        trial_df = pd.DataFrame(params, index=[0])\n",
    "        trial_df['trial_id'] = trial\n",
    "        trials_df = pd.concat([trials_df, trial_df], ignore_index=True) \n",
    "    except:\n",
    "        print('Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = trials_df.drop(['epochs', 'batch_size', 'patience','huber_delta','log_returns', 'hidden_layer6', 'hidden_layer7', 'hidden_layer8', 'hidden_layer9', 'hidden_layer10', 'loss_fn'], axis=1)\n",
    "trials_df['batch_norm'] = trials_df['batch_norm'].fillna(0)\n",
    "trials_df['l1_lambda1'] = trials_df['l1_lambda1'].fillna(0)\n",
    "trials_df['l2_lambda'] = trials_df['l2_lambda'].fillna(0)\n",
    "trials_df['dropout_prob'] = trials_df['dropout_prob'].fillna(0)\n",
    "trials_df['n_layers'] = trials_df.iloc[:,:4].astype(bool).sum(axis=1)\n",
    "trials_df['n_neurons'] = trials_df.iloc[:,:4].sum(axis=1)\n",
    "trials_df = trials_df.loc[(trials_df.act_func != 'Tanh') & (trials_df.act_func != 'Sigmoid')]\n",
    "trials_df.iloc[:,:5] = trials_df.iloc[:,:5].astype(bool).astype(int)\n",
    "\n",
    "# Remove layers info\n",
    "trials_df = trials_df.iloc[:,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = trials_df.merge(results_df[['trial_id', 'oosSpearman']], on='trial_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = trials_df.columns.to_list()#.remove(['trial_id', 'oosSpearman'])\n",
    "columns.remove('trial_id')\n",
    "columns.remove('oosSpearman')\n",
    "columns_new = ['oosSpearman']\n",
    "columns_new.extend(columns)\n",
    "trials_df = trials_df[columns_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = pd.get_dummies(trials_df, columns=['act_func','optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On long-short returns        \n",
    "X = trials_df.iloc[:, 1:]\n",
    "\n",
    "# Column 1 is long returns on max quantile, \n",
    "# Column 2 is long-short returns\n",
    "y = trials_df.iloc[:,0]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "lm = sm.OLS(y, X).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping as these are dummy variables\n",
    "trials_df = trials_df.drop(['act_func_LeakyReLU', 'optimizer_Adagrad'], axis=1)\n",
    "trials_df.iloc[:,0] = trials_df.iloc[:,0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "params = pd.DataFrame()\n",
    "tvalues = pd.DataFrame()\n",
    "\n",
    "for quantile in [0.1,0.25,0.5,0.75,0.9]:\n",
    "    # print(f'\\n\\n QUANTILE: {quantile}\\n\\n')\n",
    "    y_var = trials_df.iloc[:,0]\n",
    "    mod = smf.quantreg(f\"y_var~ {' + '.join(trials_df.columns[1:])}\", trials_df)\n",
    "\n",
    "    res = mod.fit(q=quantile)\n",
    "    params_temp = pd.DataFrame(res.params).reset_index(drop=False).rename({0:'Q'+str(int(quantile*100))}, axis=1)\n",
    "    tvalues_temp = pd.DataFrame(res.tvalues).reset_index(drop=False).rename({0:'Q'+str(int(quantile*100))}, axis=1)\n",
    "    \n",
    "    if quantile == 0.1:\n",
    "        params = pd.concat([params, params_temp])\n",
    "        tvalues = pd.concat([tvalues, tvalues_temp])\n",
    "\n",
    "    else:\n",
    "        params = params.merge(params_temp, on='index')\n",
    "        tvalues = tvalues.merge(tvalues_temp, on='index')\n",
    "\n",
    "    # params.append(res.params)\n",
    "\n",
    "    # print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('/home/ge65cuw/thesis/saved/final_results/results_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "            (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "            (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "            (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "            (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "color_index = 18\n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.  \n",
    "for i in range(len(tableau20)):  \n",
    "    r, g, b = tableau20[i]  \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)  \n",
    "path_top = path + '_feature_importance_top20.png'\n",
    "path = path + '_feature_importance.png'\n",
    "\n",
    "# x_pos = (np.arange(max['feature'])))\n",
    "\n",
    "fig = plt.figure(figsize=(12,6.5))\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = fig.add_subplot(3,2,1)\n",
    "# ax = plt.axes()\n",
    "# ax.set_title('Feature Importance', fontsize=25)\n",
    "# ax.set_xticks(x_pos)\n",
    "\n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"bottom\"].set_visible(True)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "ax.spines[\"left\"].set_visible(True)  \n",
    "# ax.set_xticklabels(results_df['FF5_Mom_STRev_alpha_VW'], rotation=90, ha='center', fontsize=12)\n",
    "# ax.bar(results_df['FF5_Mom_STRev_alpha_VW'],align='center', zorder=3, color=tableau20[color_index], height=1)\n",
    "ax.set_xlabel('7 Factor Model alpha')\n",
    "ax.hist(results_df['FF5_Mom_STRev_alpha_VW'], density=True, color=tableau20[color_index], align='mid', zorder=3)\n",
    "# plt.margins(y=0.01, x=.005)\n",
    "ax.xaxis.grid(True, linestyle='--',  zorder=0)\n",
    "ax.yaxis.grid(True, linestyle='--',  zorder=0)\n",
    "\n",
    "ax = fig.add_subplot(3,2,2)\n",
    "\n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"bottom\"].set_visible(True)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "ax.spines[\"left\"].set_visible(True)  \n",
    "color_index = 16\n",
    "ax.hist(results_df['oosSpearman'], density=True, zorder=3, color=tableau20[color_index], align='mid')\n",
    "ax.set_xlabel('Out of Sample Spearman Coefficient')\n",
    "# plt.margins(y=0.01, x=.005)\n",
    "ax.xaxis.grid(True, linestyle='--',  zorder=0)\n",
    "ax.yaxis.grid(True, linestyle='--',  zorder=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4804d781847468e0794096453e716a44bf82c4d93fcc1a726a520e37d704781"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
