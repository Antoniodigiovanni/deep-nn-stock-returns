{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add root folder to Python path (to import modules)\n",
    "notebook_dir = Path().absolute()\n",
    "project_root = notebook_dir.parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data.dataset import BaseDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime as dt\n",
    "from data.crsp_dataset import CrspDataset\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from torch.utils.data import DataLoader\n",
    "from src.portfolios.ReturnsPrediction import ReturnsPrediction\n",
    "from src.models.neural_net.Optimize_Net import OptimizeNet\n",
    "import tuning.tuning_utils as tu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Captum imports\n",
    "from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
    "from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation\n",
    "\n",
    "path = '../saved/final_results/img/feature_importance/'\n",
    "path_for_model = '../results/ModelInterpretation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000 #5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_importances(feature_names, importances, path, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\", color_index = 5):\n",
    "    \n",
    "    importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    importance_df_reindexed = importance_df.reindex(importance_df.importance.abs().sort_values(ascending=False).index)\n",
    "    importance_df_top = importance_df_reindexed.head(20) \n",
    "    importance_df = importance_df.sort_values(by='importance',ascending=True)\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "\n",
    "        # Remove the plot frame lines. They are unnecessary chartjunk.\n",
    "        # These are the \"Tableau 20\" colors as RGB.  \n",
    "        tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "                    (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "                    (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "                    (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "                    (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "\n",
    "        # Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.  \n",
    "        for i in range(len(tableau20)):  \n",
    "            r, g, b = tableau20[i]  \n",
    "            tableau20[i] = (r / 255., g / 255., b / 255.)  \n",
    "        path_top = path + '_fi_top20.png'\n",
    "        default_path = path + '_fi_full.png'\n",
    "        print(path)\n",
    "        print(path_top)\n",
    "        # path = path + '_feature_importance.png'\n",
    "        path_categorized = path + '_fi_categorized.png'\n",
    "        path_transposed = path + '_fi_full_transposed.png'\n",
    "\n",
    "        x_pos = (np.arange(len(importance_df['feature'])))\n",
    "\n",
    "        fig = plt.figure(figsize=(24,12))\n",
    "        ax = plt.axes()\n",
    "        ax.set_xticks(x_pos)\n",
    "        \n",
    "        ax.spines[\"top\"].set_visible(False)  \n",
    "        ax.spines[\"bottom\"].set_visible(True)  \n",
    "        ax.spines[\"right\"].set_visible(False)  \n",
    "        ax.spines[\"left\"].set_visible(True)  \n",
    "        ax.set_xticklabels(importance_df['feature'], rotation=90, ha='center', fontsize=12)\n",
    "        ax.bar(x_pos, importance_df['importance'],align='center', zorder=3, color=tableau20[color_index])\n",
    "        plt.margins(y=0.01, x=.005)\n",
    "        plt.axhline(y=0, color='grey', linestyle='-')\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(default_path)\n",
    "        \n",
    "\n",
    "        # Transposed plot\n",
    "        y_pos = (np.arange(len(importance_df['feature'])))\n",
    "\n",
    "        fig = plt.figure(figsize=(8,35))\n",
    "        ax = plt.axes()\n",
    "        # ax.set_title('Feature Importance', fontsize=25)\n",
    "        ax.set_yticks(y_pos)\n",
    "        \n",
    "        ax.spines[\"top\"].set_visible(False)  \n",
    "        ax.spines[\"bottom\"].set_visible(True)  \n",
    "        ax.spines[\"right\"].set_visible(False)  \n",
    "        ax.spines[\"left\"].set_visible(True)  \n",
    "        ax.set_yticklabels(importance_df['feature'], rotation=0, fontsize=18)\n",
    "        ax.xaxis.labelpad = 0\n",
    "        ax.barh(y_pos, importance_df['importance'], align='center', zorder=3, color=tableau20[color_index])\n",
    "        plt.margins(x=0.01, y=.001)\n",
    "        # ax.xaxis.grid(True, linestyle='--',  zorder=0)\n",
    "        plt.axvline(x=0, color='grey', linestyle='-')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(path_transposed)\n",
    "        \n",
    "\n",
    "\n",
    "        # Top 20 plot - transposed\n",
    "        importance_df_top = importance_df_top.sort_values(by='importance')\n",
    "        y_pos = (np.arange(len(importance_df_top['feature'])))\n",
    "\n",
    "        fig = plt.figure(figsize=(12,9))\n",
    "        ax = plt.axes()\n",
    "        ax.get_xaxis().tick_bottom()\n",
    "        ax.get_yaxis().tick_left()\n",
    "\n",
    "        ax.spines[\"top\"].set_visible(False)  \n",
    "        ax.spines[\"bottom\"].set_visible(True)  \n",
    "        ax.spines[\"right\"].set_visible(False)  \n",
    "        ax.spines[\"left\"].set_visible(True)  \n",
    "\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(importance_df_top['feature'], rotation=0, ha='right', fontsize=16)\n",
    "            \n",
    "        ax.barh(y_pos, importance_df_top['importance'],align='center',  zorder=3, color=tableau20[color_index])\n",
    "        # ax.yaxis.grid(True, linestyle='--',  zorder=0)\n",
    "        ax.xaxis.grid(True, linestyle='--',  zorder=0)\n",
    "        plt.axvline(x=0, color='grey', linestyle='-')\n",
    "        fig.tight_layout()\n",
    "        plt.margins(x=.05, y=.05)\n",
    "        plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "        # plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(path_top)\n",
    "\n",
    "        # Plot by factor categories\n",
    "\n",
    "        importance_df['cat'] = np.nan\n",
    "        factors =  {\n",
    "            'profitability': [\n",
    "                'roaq',\n",
    "                'CBOperProf',\n",
    "                # 'Investment',\n",
    "                # 'InvestPPEInv'\n",
    "                ],\n",
    "            'market': [\n",
    "                'BetaLiquidityPS',\n",
    "                'BetaTailRisk',\n",
    "                'betaVIX',\n",
    "                'SmileSlope',\n",
    "                # 'std_turn'\n",
    "                ],\n",
    "            'growth': [\n",
    "                'AssetGrowth',\n",
    "                'ChEQ',\n",
    "                'ChInv',\n",
    "                'GrAdExp',\n",
    "                # 'hire',\n",
    "                # 'InvGrowth'\n",
    "                ],\n",
    "        'quality': [\n",
    "            'fgr5yrLag',\n",
    "            'FEPS',\n",
    "            'BookLeverage',\n",
    "            'NetDebtPrice'\n",
    "        ],\n",
    "        'value': [\n",
    "            # 'Accruals',\n",
    "            'AccrualsBM',\n",
    "            'AM',\n",
    "            'BMdec',\n",
    "            # 'BookLeverage',\n",
    "            # 'BPEBM',\n",
    "            # 'EarningsStreak',\n",
    "            # 'CF',\n",
    "            'RDcap',\n",
    "            # 'EP'\n",
    "            ],\n",
    "            'momentum':[\n",
    "                'Mom12m',\n",
    "                'Mom6m',\n",
    "                'MomSeason',\n",
    "                'MomOffSeason'\n",
    "                # 'MomSeasonShort'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Transposed plot by category\n",
    "        i=0\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        for k,v in factors.items():\n",
    "            i += 1\n",
    "            imp_df = importance_df.loc[importance_df.feature.isin(v)].copy()\n",
    "            ax = fig.add_subplot(2,3,i)\n",
    "            \n",
    "            y_pos = (np.arange(len(imp_df['feature'])))\n",
    "            ax.get_xaxis().tick_bottom()\n",
    "            ax.get_yaxis().tick_left()\n",
    "\n",
    "            ax.spines[\"top\"].set_visible(False)  \n",
    "            ax.spines[\"bottom\"].set_visible(True)  \n",
    "            ax.spines[\"right\"].set_visible(False)  \n",
    "            ax.spines[\"left\"].set_visible(True)  \n",
    "\n",
    "            ax.set_yticks(y_pos)\n",
    "            ax.set_yticklabels(imp_df['feature'], rotation=0, ha='right', fontsize=14)\n",
    "            ax.barh(y_pos, imp_df['importance'], align='center',  zorder=3, color=tableau20[color_index])#, height=0.8)\n",
    "            ax.set_title(k.capitalize())\n",
    "            ax.xaxis.grid(True, linestyle='--',  zorder=0)\n",
    "            plt.margins(x=.05, y=.05)\n",
    "            plt.axvline(x=0, color='grey', linestyle='-')\n",
    "            fig.tight_layout()\n",
    "            plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(path_categorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_importances(feature_names, importances, path, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\", color_index = 5):\n",
    "    \n",
    "    importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    importance_df_reindexed = importance_df.reindex(importance_df.importance.abs().sort_values(ascending=False).index)\n",
    "    importance_df_top = importance_df_reindexed.head(20) \n",
    "    importance_df = importance_df.sort_values(by='importance',ascending=True)\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "\n",
    "        tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "                    (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "                    (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "                    (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "                    (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "\n",
    "        for i in range(len(tableau20)):  \n",
    "            r, g, b = tableau20[i]  \n",
    "            tableau20[i] = (r / 255., g / 255., b / 255.)  \n",
    "        path_top = path + '_fi_top20.png'\n",
    "        default_path = path + '_fi_full.png'\n",
    "        path_categorized = path + '_fi_categorized.png'\n",
    "        path_transposed = path + '_fi_full_transposed.png'\n",
    "\n",
    "      \n",
    "        # Top 20 plot - transposed\n",
    "        importance_df_top = importance_df_top.sort_values(by='importance')\n",
    "        y_pos = (np.arange(len(importance_df_top['feature'])))\n",
    "\n",
    "        fig = plt.figure(figsize=(17,15))\n",
    "        ax = plt.axes()\n",
    "        ax.get_xaxis().tick_bottom()\n",
    "        ax.get_yaxis().tick_left()\n",
    "\n",
    "        ax.spines[\"top\"].set_visible(False)  \n",
    "        ax.spines[\"bottom\"].set_visible(True)  \n",
    "        ax.spines[\"right\"].set_visible(False)  \n",
    "        ax.spines[\"left\"].set_visible(True)  \n",
    "\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(importance_df_top['feature'], rotation=0, ha='right', fontsize=16)\n",
    "            \n",
    "        ax.barh(y_pos, importance_df_top['importance'],align='center',  zorder=3, color=tableau20[color_index])\n",
    "        ax.xaxis.grid(True, linestyle='--',  zorder=0)\n",
    "        plt.axvline(x=0, color='grey', linestyle='-')\n",
    "        plt.margins(x=.05, y=.05)\n",
    "        plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "        plt.tight_layout()\n",
    "        fig.show()\n",
    "        print(path_top)\n",
    "        fig.savefig(path_top)\n",
    "\n",
    "        # Plot by factor categories\n",
    "\n",
    "        importance_df['cat'] = np.nan\n",
    "        factors =  {\n",
    "            'profitability': ['roaq','CBOperProf'],\n",
    "            'market': ['BetaLiquidityPS','BetaTailRisk','betaVIX','SmileSlope'],\n",
    "            'growth': [\n",
    "                'AssetGrowth',\n",
    "                'ChEQ',\n",
    "                'ChInv',\n",
    "                'GrAdExp',\n",
    "                ],\n",
    "        'quality': ['fgr5yrLag','FEPS','BookLeverage','NetDebtPrice'],\n",
    "        'value': ['AccrualsBM','AM','BMdec','RDcap',],\n",
    "        'momentum':[\n",
    "                'Mom12m',\n",
    "                'Mom6m',\n",
    "                'MomSeason',\n",
    "                'MomOffSeason'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Transposed plot by category\n",
    "        i=0\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        for k,v in factors.items():\n",
    "            i += 1\n",
    "            imp_df = importance_df.loc[importance_df.feature.isin(v)].copy()\n",
    "            ax = fig.add_subplot(2,3,i)\n",
    "            \n",
    "            y_pos = (np.arange(len(imp_df['feature'])))\n",
    "            ax.get_xaxis().tick_bottom()\n",
    "            ax.get_yaxis().tick_left()\n",
    "\n",
    "            ax.spines[\"top\"].set_visible(False)  \n",
    "            ax.spines[\"bottom\"].set_visible(True)  \n",
    "            ax.spines[\"right\"].set_visible(False)  \n",
    "            ax.spines[\"left\"].set_visible(True)  \n",
    "\n",
    "            ax.set_yticks(y_pos)\n",
    "            ax.set_yticklabels(imp_df['feature'], rotation=0, ha='right', fontsize=14)\n",
    "            ax.barh(y_pos, imp_df['importance'], align='center',  zorder=3, color=tableau20[color_index])#, height=0.8)\n",
    "            ax.set_title(k.capitalize())\n",
    "            ax.xaxis.grid(True, linestyle='--',  zorder=0)\n",
    "            plt.margins(x=.05, y=.05)\n",
    "            plt.axvline(x=0, color='grey', linestyle='-')\n",
    "            fig.tight_layout()\n",
    "            plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(path_categorized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Net = 'model_16684133429276826.pt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BaseDataset()\n",
    "df = dataset.df\n",
    "df = df.drop('Beta',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.columns.to_list().index('ret')+1\n",
    "feature_names = df.columns.to_list()[idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = list(\n",
    "    pd.period_range(\n",
    "        start= (dt.datetime.strptime(str(202012), '%Y%m') + DateOffset(months=1)),\n",
    "        periods=12,\n",
    "        freq='M'\n",
    "        ).strftime('%Y%m')\n",
    "        .astype(int)\n",
    "        )\n",
    "train_dates = list(\n",
    "    pd.period_range(\n",
    "        start= (dt.datetime.strptime(str(198912), '%Y%m') + DateOffset(months=1)),\n",
    "        periods=12*25,\n",
    "        freq='M'\n",
    "        ).strftime('%Y%m')\n",
    "        .astype(int)\n",
    "        )        \n",
    "\n",
    "train = df.loc[df['yyyymm'].isin(train_dates)].copy()\n",
    "test = df.loc[df['yyyymm'].isin(test_dates)].copy()\n",
    "\n",
    "train = CrspDataset(train)\n",
    "test = CrspDataset(test)\n",
    "\n",
    "n_inputs = test.get_inputs()\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "train_inputs, train_target, train_labels = train_iter.next()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "inputs, target, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"hidden_layer1\": 512,\n",
    "        \"hidden_layer2\": 256,\n",
    "        \"hidden_layer3\": 64,\n",
    "        \"hidden_layer4\": 0,\n",
    "        \"hidden_layer5\": 0,\n",
    "        \"hidden_layer6\": 0,\n",
    "        \"hidden_layer7\": 0,\n",
    "        \"hidden_layer8\": 0,\n",
    "        \"hidden_layer9\": 0,\n",
    "        \"hidden_layer10\": 0,\n",
    "        \"act_func\": \"ReLU\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"optimizer\":    \"Nadam\",\n",
    "        \"l1_lambda1\":   0.001,\n",
    "        \"dropout_prob\": 0.7,\n",
    "        'batch_norm':   1,\n",
    "        'patience':     10 \n",
    "    } \n",
    "model = OptimizeNet(n_inputs=n_inputs, params=params)\n",
    "optimizer = tu.map_optimizer(params, model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path_for_model + 'models/' + Top_Net\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = inputs.float()\n",
    "X_test.requires_grad_()\n",
    "\n",
    "X_train = train_inputs.float()\n",
    "X_train.requires_grad_()\n",
    "\n",
    "ig = IntegratedGradients(model)\n",
    "ig_nt = NoiseTunnel(ig)\n",
    "# dl = DeepLift(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)\n",
    "\n",
    "nn3_ig_attr, delta = ig.attribute(X_test, return_convergence_delta=True)\n",
    "# ig_nt_attr_test = ig_nt.attribute(X_test)\n",
    "# dl_attr_test = dl.attribute(X_test)\n",
    "# gs_attr_nn3_test = gs.attribute(X_test, X_train)\n",
    "# fa_attr_test = fa.attribute(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = path + 'nn3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn3_attr = nn3_ig_attr.to('cpu').detach().numpy()\n",
    "visualize_importances(feature_names, np.mean(nn3_attr, axis=0), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn3_importances = np.mean(nn3_attr, axis=0)\n",
    "nn3_importance_df = pd.DataFrame({'feature': feature_names, 'nn3_importance': nn3_importances})\n",
    "nn3_importance_df = nn3_importance_df.sort_values(by='feature', ascending=False)\n",
    "nn3_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gu Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gu_net = 'model_16684484170777052.pt'\n",
    "dataset = BaseDataset()\n",
    "df = dataset.df\n",
    "df = df.drop('Beta',axis=1)\n",
    "\n",
    "\n",
    "idx = df.columns.to_list().index('ret')+1\n",
    "feature_names = df.columns.to_list()[idx:]\n",
    "\n",
    "test_dates = list(\n",
    "    pd.period_range(\n",
    "        start= (dt.datetime.strptime(str(202012), '%Y%m') + DateOffset(months=1)),\n",
    "        periods=12,\n",
    "        freq='M'\n",
    "        ).strftime('%Y%m')\n",
    "        .astype(int)\n",
    "        )\n",
    "train_dates = list(\n",
    "    pd.period_range(\n",
    "        start= (dt.datetime.strptime(str(198912), '%Y%m') + DateOffset(months=1)),\n",
    "        periods=12*25,\n",
    "        freq='M'\n",
    "        ).strftime('%Y%m')\n",
    "        .astype(int)\n",
    "        )        \n",
    "\n",
    "train = df.loc[df['yyyymm'].isin(train_dates)].copy()\n",
    "test = df.loc[df['yyyymm'].isin(test_dates)].copy()\n",
    "\n",
    "train = CrspDataset(train)\n",
    "test = CrspDataset(test)\n",
    "\n",
    "n_inputs = test.get_inputs()\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "train_inputs, train_target, train_labels = train_iter.next()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "inputs, target, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path_for_model + 'models/' + Gu_net\n",
    "checkpoint = torch.load(model_path)\n",
    "checkpoint['params']['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.neural_net.gu_et_al_NN4 import GuNN4\n",
    "model = GuNN4(n_inputs)\n",
    "\n",
    "model_path = path_for_model + 'models/' + Gu_net\n",
    "checkpoint = torch.load(model_path)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "            checkpoint['params']['learning_rate'],\n",
    "            # Uncomment when will be using them as parameters\n",
    "            betas=(\n",
    "                checkpoint['params']['adam_beta_1'], \n",
    "                checkpoint['params']['adam_beta_2'])\n",
    "                )\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = inputs.float()\n",
    "X_test.requires_grad_()\n",
    "\n",
    "X_train = train_inputs.float()\n",
    "X_train.requires_grad_()\n",
    "\n",
    "ig = IntegratedGradients(model)\n",
    "ig_nt = NoiseTunnel(ig)\n",
    "# dl = DeepLift(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)\n",
    "\n",
    "gu_ig_attr, delta = ig.attribute(X_test, return_convergence_delta=True)\n",
    "# ig_nt_attr_test = ig_nt.attribute(X_test)\n",
    "# dl_attr_test = dl.attribute(X_test)\n",
    "# gs_attr_gu_test = gs.attribute(X_test, X_train)\n",
    "# fa_attr_test = fa.attribute(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = path + 'gu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_attr = gu_ig_attr.to('cpu').detach().numpy()\n",
    "visualize_importances(feature_names, np.mean(gu_attr, axis=0), save_path, color_index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert importances to LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_importances = np.mean(gu_attr, axis=0)\n",
    "gu_importance_df = pd.DataFrame({'feature': feature_names, 'gu_importance': gu_importances})\n",
    "gu_importance_df = gu_importance_df.sort_values(by='gu_importance', ascending=False)\n",
    "gu_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = nn3_importance_df.merge(gu_importance_df, on='feature')\n",
    "importances.to_csv('/home/ge65cuw/thesis/saved/final_results/integrated_gradients.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('/home/ge65cuw/thesis/saved/final_results/integrated_gradients.csv', index_col=0)\n",
    "pd.set_option('display.float_format', '{:.2E}'.format)\n",
    "importances = importances.sort_values(by='feature')\n",
    "# importances\n",
    "print(importances.style.hide(axis=\"index\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importances.style.hide(axis=\"index\").to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4804d781847468e0794096453e716a44bf82c4d93fcc1a726a520e37d704781"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
